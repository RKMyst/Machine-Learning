{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7 - Cartoonify faces\n",
    "## Instructions\n",
    "This task tests your ability to apply Video processing and Face detection techniques to place a cartoon mask instead of your face in the video.\n",
    "\n",
    "Please take the help of the attached notebook which contains the helper code to detect faces from webcam video.\n",
    "\n",
    "Submit\n",
    "\n",
    "1. Python Notebook (IPYNB)\n",
    "\n",
    "2. Cartoon mask (JPG/PNG)\n",
    "\n",
    "3. Video (wav/mp3) OR Screenshot Image (JPG/PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##To complete this assignment, you need to create a Python notebook that processes video to detect faces and apply a cartoon mask over them. Hereâ€™s a step-by-step guide on how you can approach this task:\n",
    "\n",
    "### 1. Python Notebook (IPYNB)\n",
    "You need to create a Jupyter notebook (`IPYNB` file) that includes the following components:\n",
    "\n",
    "#### a. Video Processing:\n",
    "- Import necessary libraries (like OpenCV).\n",
    "- Capture video from the webcam.\n",
    "- Process the video frame by frame.\n",
    "\n",
    "#### b. Face Detection:\n",
    "- Use a face detection model (like a pre-trained Haar Cascade classifier or a Dlib model) to detect faces in each frame.\n",
    "- For each detected face, get the coordinates of the face region.\n",
    "\n",
    "#### c. Applying Cartoon Mask:\n",
    "- Prepare or choose a cartoon mask image that you will overlay on the detected faces.\n",
    "- Resize the cartoon mask to match the size of the detected face region.\n",
    "- Overlay the cartoon mask on the face region in each frame.\n",
    "\n",
    "#### d. Output:\n",
    "- Display the modified video frames in real-time.\n",
    "- Optionally, save the output as a video file.\n",
    "\n",
    "### 2. Cartoon Mask (JPG/PNG)\n",
    "Create or find a cartoon mask image. This image will be overlaid on the detected faces. Ensure the mask is suitable for various face sizes and orientations.\n",
    "\n",
    "### 3. Video (wav/mp3) OR Screenshot Image (JPG/PNG)\n",
    "You can either:\n",
    "- Record a short video demonstrating your project in action and save it in a common format like `.wav` or `.mp3`.\n",
    "- Take a screenshot image of your program running and showing the cartoon mask applied on a face. Save this image in either JPG or PNG format.\n",
    "\n",
    "### Notes:\n",
    "- Remember to comment your code adequately for clarity.\n",
    "- Test the notebook to ensure it works as expected before submission.\n",
    "- Ensure all dependencies are listed, so your notebook can be run on another machine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the cartoon mask image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image_path = 'funnycat.png' # Path to the mask image\n",
    "mask_image = cv2.imread(mask_image_path, -1)\n",
    "mask_image = cv2.resize(mask_image, (200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to apply mask to a face\n",
    "def apply_mask(frame, face_coordinates, mask):\n",
    "    (x, y, w, h) = face_coordinates\n",
    "\n",
    "    # Resize mask to fit the face\n",
    "    mask_resized = cv2.resize(mask, (w, h))\n",
    "\n",
    "    # Calculate coordinates for placing the mask\n",
    "    mask_x1 = x\n",
    "    mask_x2 = x + w\n",
    "    mask_y1 = y\n",
    "    mask_y2 = y + h\n",
    "\n",
    "    # Extract alpha channel from mask image\n",
    "    alpha_mask = mask_resized[:, :, 3] / 255.0\n",
    "    alpha_frame = 1.0 - alpha_mask\n",
    "\n",
    "    # Apply mask to the region of the face\n",
    "    for c in range(0, 3):\n",
    "        frame[mask_y1:mask_y2, mask_x1:mask_x2, c] = (alpha_mask * mask_resized[:, :, c] +\n",
    "                                                      alpha_frame * frame[mask_y1:mask_y2, mask_x1:mask_x2, c])\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load pre-trained face detection model (Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    # Apply mask to each face\n",
    "    for face_coordinates in faces:\n",
    "        frame = apply_mask(frame, face_coordinates, mask_image)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Break the loop with the 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the Haar cascade file\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Start the webcam\n",
    "cap = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cascade\n",
    "face_cascade_path = 'haarcascade_frontalface_default.xml'  # Replace with your actual path\n",
    "\n",
    "# Create the cascade\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "\n",
    "# Load the cascade from the file\n",
    "loaded = face_cascade.load(face_cascade_path)\n",
    "\n",
    "# Check if the cascade is loaded correctly\n",
    "if not loaded:\n",
    "    print(f'Error loading cascade from {face_cascade_path}')\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the Haar cascade file\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Start the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load the mask image - replace with the actual path\n",
    "mask = cv2.imread('funnycat.png', 0)  \n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Define the face section\n",
    "        face_section = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize and apply the mask\n",
    "        resized_mask = cv2.resize(mask, (w, h))\n",
    "        masked_face = cv2.bitwise_and(face_section, face_section, mask=resized_mask)\n",
    "\n",
    "        # Place the masked face back into the frame\n",
    "        frame[y:y+h, x:x+w] = masked_face\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Break the loop with the 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/maple/Library/Mobile Documents/com~apple~CloudDocs/Artificial Intelligence/AI GBC/AASD 4004 MACHINE LEARNING II AASD 4004/Assignment/Task 7 - Cartoonify faces/Kajhonprom_Task 7 - Cartoonify faces.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maple/Library/Mobile%20Documents/com~apple~CloudDocs/Artificial%20Intelligence/AI%20GBC/AASD%204004%20MACHINE%20LEARNING%20II%20AASD%204004/Assignment/Task%207%20-%20Cartoonify%20faces/Kajhonprom_Task%207%20-%20Cartoonify%20faces.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maple/Library/Mobile%20Documents/com~apple~CloudDocs/Artificial%20Intelligence/AI%20GBC/AASD%204004%20MACHINE%20LEARNING%20II%20AASD%204004/Assignment/Task%207%20-%20Cartoonify%20faces/Kajhonprom_Task%207%20-%20Cartoonify%20faces.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maple/Library/Mobile%20Documents/com~apple~CloudDocs/Artificial%20Intelligence/AI%20GBC/AASD%204004%20MACHINE%20LEARNING%20II%20AASD%204004/Assignment/Task%207%20-%20Cartoonify%20faces/Kajhonprom_Task%207%20-%20Cartoonify%20faces.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Output: htt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maple/Library/Mobile%20Documents/com~apple~CloudDocs/Artificial%20Intelligence/AI%20GBC/AASD%204004%20MACHINE%20LEARNING%20II%20AASD%204004/Assignment/Task%207%20-%20Cartoonify%20faces/Kajhonprom_Task%207%20-%20Cartoonify%20faces.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maple/Library/Mobile%20Documents/com~apple~CloudDocs/Artificial%20Intelligence/AI%20GBC/AASD%204004%20MACHINE%20LEARNING%20II%20AASD%204004/Assignment/Task%207%20-%20Cartoonify%20faces/Kajhonprom_Task%207%20-%20Cartoonify%20faces.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Path: Kajhonprom_Task 8 - Face Recognition.ipynb\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Output: htt\n",
    "\n",
    "# Path: Kajhonprom_Task 8 - Face Recognition.ipynb\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# KNN Code\n",
    "def distance(v1, v2):\n",
    "    # Eucledian\n",
    "    return np.sqrt(((v1-v2)**2).sum())\n",
    "\n",
    "def knn(train, test, k=5):\n",
    "    dist = []\n",
    "    \n",
    "    for i in range(train.shape[0]):\n",
    "        # Get the vector and label\n",
    "        ix = train[i, :-1]\n",
    "        iy = train[i, -1]\n",
    "        # Compute the distance from test point\n",
    "        d = distance(test, ix)\n",
    "        dist.append([d, iy])\n",
    "        \n",
    "    # Sort based on distance and get top k\n",
    "    dk = sorted(dist, key=lambda x: x[0])[:k]\n",
    "    # Retrieve only the labels\n",
    "    labels = np.array(dk)[:, -1]\n",
    "    \n",
    "    # Get frequencies of each label\n",
    "    output = np.unique(labels, return_counts=True)\n",
    "    # Find max frequency and corresponding label\n",
    "    index = np.argmax(output[1])\n",
    "    return output[0][index]\n",
    "\n",
    "# Init Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Face Detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "skip = 0\n",
    "dataset_path = './data/'\n",
    "\n",
    "face_data = []\n",
    "labels = []\n",
    "\n",
    "class_id = 0 # Labels for the given file\n",
    "names = {} # Mapping btw id - name\n",
    "\n",
    "# Data Preparation\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        # Create a mapping btw class_id and name\n",
    "        names[class_id] = fx[:-4]\n",
    "        print('Loaded '+fx)\n",
    "        data_item = np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "        \n",
    "        # Create Labels for the class\n",
    "        target = class_id*np.ones((data_item.shape[0],))\n",
    "        class_id += 1\n",
    "        labels.append(target)\n",
    "\n",
    "face_dataset = np.concatenate(face_data, axis=0)\n",
    "face_labels = np.concatenate(labels, axis=0).reshape((-1, 1))\n",
    "\n",
    "print(face_dataset.shape)\n",
    "print(face_labels.shape)\n",
    "\n",
    "trainset = np.concatenate((face_dataset, face_labels), axis=1)\n",
    "print(trainset.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T431",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
